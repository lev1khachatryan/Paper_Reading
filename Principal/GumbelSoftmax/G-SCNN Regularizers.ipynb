{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge consistency and edge potentials\n",
    "\n",
    "Partial implementation of the paper [Gated-SCNN: Gated Shape CNNs for Semantic Segmentation](https://arxiv.org/pdf/1907.05740.pdf)\n",
    "\n",
    "[Gumbel-Max Trick](https://laurent-dinh.github.io/2016/11/22/gumbel-max.html)\n",
    "\n",
    "[Categorical reparameterization with gumbel-softmax](https://arxiv.org/pdf/1611.01144.pdf)\n",
    "\n",
    "[The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables](https://arxiv.org/pdf/1611.00712.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balanced_cross_entropy(logits, labels, name='balanced_cross_entropy_loss'):\n",
    "    \"\"\"\n",
    "    The class-balanced cross entropy loss\n",
    "    Args:\n",
    "        logits: of shape (b, ...).\n",
    "        labels: of the same shape. the ground truth in {0,1}.\n",
    "    Returns:\n",
    "        class-balanced cross entropy loss.\n",
    "    \"\"\"\n",
    "    # with tf.name_scope('class_balanced_binary_cross_entropy'):\n",
    "    y = tf.cast(labels, tf.float32)\n",
    "\n",
    "    count_neg = tf.reduce_sum(1. - y)\n",
    "    count_pos = tf.reduce_sum(y)\n",
    "    beta = count_neg / (count_neg + count_pos)\n",
    "\n",
    "    pos_weight = beta / (1 - beta)\n",
    "    neg_weight = tf.ones_like(pos_weight, dtype=tf.float32)\n",
    "    class_weights = tf.stack([neg_weight, pos_weight], 0)\n",
    "\n",
    "    weights = tf.gather(class_weights, labels)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits, weights=weights)\n",
    "    # loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits, weights=weights)\n",
    "    return loss\n",
    "\n",
    "def semantic_edge_consistency_regularizer(gt, pred, pred_1st, thresh=0.8):\n",
    "    \"\"\"\n",
    "    :param gt [b, h, w, c]:\n",
    "    :param pred [b, h, w, c]:\n",
    "    :param pred_1st [b, h, w, 1]:\n",
    "    :param thresh probability to consider an edge in our prediction:\n",
    "    :return cross entropy of classifications near on an edge:\n",
    "     whereever we have predicted an edge, calculated the cross entropy there.\n",
    "    This penalises the edges more strongly, encouraging them to be correct at the boundary\n",
    "    \"\"\"\n",
    "    mask = tf.stop_gradient(tf.cast((pred_1st > thresh), tf.float32))\n",
    "    mask = tf.expand_dims(mask, axis=-1)\n",
    "    gt = tf.stop_gradient(tf.cast(gt, tf.float32))\n",
    "    pred = tf.stop_gradient(tf.cast(pred, tf.float32))\n",
    "    pred = tf.math.multiply(pred, mask)\n",
    "    gt = tf.math.multiply(gt, mask)\n",
    "\n",
    "    # return tf.reduce_mean(tf.losses.categorical_crossentropy(gt, pred, from_logits=True))\n",
    "    return tf.reduce_mean(tf.compat.v2.losses.categorical_crossentropy(gt, pred, from_logits=True))\n",
    "\n",
    "def semantic_edge_potential_regularizer(gt, pred, thresh=0.8):\n",
    "    \"\"\"\n",
    "    :param gt [b, h, w, c] segmentation labels:\n",
    "    :param pred [b, h, w, c] segmentation logits:\n",
    "    :param thresh intensity to be considered edge:\n",
    "    :return the difference in boundaries between predicted versus actual\n",
    "            where the boundaries come from the 2nd, rather than the 1st stage:\n",
    "    \"\"\"\n",
    "    def _gumbel_softmax(logits, eps=1e-8, tau=1.):\n",
    "        \"\"\"\n",
    "        :param logits:\n",
    "        :param eps:\n",
    "        :param tau temprature:\n",
    "        :return soft approximation to argmax:\n",
    "        see https://arxiv.org/abs/1611.01144\n",
    "        \"\"\"\n",
    "        g = tf.random.uniform(tf.shape(logits))\n",
    "        g = -tf.math.log(eps - tf.math.log(g + eps))\n",
    "        return tf.nn.softmax((logits + g) / tau)\n",
    "\n",
    "    def _all_close(x, y, rtol=1e-5, atol=1e-8):\n",
    "        return tf.reduce_all(tf.abs(x - y) <= tf.abs(y) * rtol + atol)\n",
    "\n",
    "    def _gradient_mag(tensor, from_rgb=False, eps=1e-12):\n",
    "        if from_rgb:\n",
    "            tensor = tf.image.rgb_to_grayscale(tensor[..., :3])\n",
    "        tensor_edge = tf.image.sobel_edges(tensor)\n",
    "\n",
    "        def _normalised_mag():\n",
    "            mag = tf.reduce_sum(tensor_edge ** 2, axis=-1) + eps\n",
    "            mag = tf.math.sqrt(mag)\n",
    "            mag /= tf.reduce_max(mag, axis=[1, 2], keepdims=True)\n",
    "            return mag\n",
    "\n",
    "        z = tf.zeros_like(tensor)\n",
    "        normalised_mag = tf.cond(\n",
    "            _all_close(tensor_edge, tf.zeros_like(tensor_edge)),\n",
    "            lambda: z,\n",
    "            _normalised_mag, \n",
    "            name='potato')\n",
    "\n",
    "        return normalised_mag\n",
    "\n",
    "    # gt = tf.stop_gradient(tf.cast(gt, tf.float32))\n",
    "    gt = tf.cast(gt, tf.float32)\n",
    "    # soft approximation to argmax, so we can build an edge\n",
    "    pred = _gumbel_softmax(pred)  ## --\n",
    "\n",
    "    # normalised image gradients to give us edges\n",
    "    # images will be [b, h, w, n_classes]\n",
    "    gt_edges = _gradient_mag(gt)\n",
    "    pred_edges = _gradient_mag(pred)\n",
    "\n",
    "    # [b*h*w, n]\n",
    "    gt_edges = tf.reshape(gt_edges, [-1, tf.shape(gt_edges)[-1]])\n",
    "    pred_edges = tf.reshape(pred_edges, [-1, tf.shape(gt_edges)[-1]])\n",
    "\n",
    "    # take the difference between these two gradient magnitudes\n",
    "    # we will first take all the edges from the ground truth image\n",
    "    # and then all the edges from the predicted\n",
    "    edge_difference = tf.abs(gt_edges - pred_edges)\n",
    "\n",
    "    # gt edges and disagreement with pred\n",
    "    mask_gt = tf.cast((gt_edges > thresh ** 2), tf.float32)\n",
    "    contrib_0 = tf.boolean_mask(edge_difference, mask_gt)\n",
    "\n",
    "    contrib_0 = tf.cond(\n",
    "        tf.greater(tf.size(contrib_0), 0),\n",
    "        lambda: tf.reduce_mean(contrib_0),\n",
    "        lambda: 0.)\n",
    "\n",
    "    # vice versa\n",
    "    # mask_pred = tf.stop_gradient(tf.cast((pred_edges > thresh ** 2), tf.float32))\n",
    "    mask_pred = tf.cast((pred_edges > thresh ** 2), tf.float32)\n",
    "    contrib_1 = tf.reduce_mean(tf.boolean_mask(edge_difference, mask_pred))\n",
    "    contrib_1 = tf.cond(\n",
    "        tf.greater(tf.size(contrib_1), 0),\n",
    "        lambda: tf.reduce_mean(contrib_1),\n",
    "        lambda: 0.)\n",
    "    return tf.reduce_mean(0.5 * contrib_0 + 0.5 * contrib_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "a = tf.random.uniform((2, 25, 25, 3), minval=0, maxval=2, dtype=tf.dtypes.int32)\n",
    "b = tf.random.uniform((2, 25, 25, 3), minval=0, maxval=2, dtype=tf.dtypes.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = sess.run(a)\n",
    "pd = sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = semantic_edge_potential_regularizer(gt, pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = tf.cast(gt, tf.float32)\n",
    "pred = _gumbel_softmax(pd)\n",
    "\n",
    "gt_edges = _gradient_mag(gt)\n",
    "pred_edges = _gradient_mag(pred)\n",
    "\n",
    "gt_edges = tf.reshape(gt_edges, [-1, tf.shape(gt_edges)[-1]])\n",
    "pred_edges = tf.reshape(pred_edges, [-1, tf.shape(gt_edges)[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_edge = tf.image.sobel_edges(gt)\n",
    "z = tf.zeros_like(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddxk = _all_close(tensor_edge, tf.zeros_like(tensor_edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 25, 25, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.reduce_sum(tensor_edge ** 2, axis=-1)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
